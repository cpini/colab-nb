{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fsbQpUPpQ4BH"
      },
      "outputs": [],
      "source": [
        "# Copyright 2023 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHa16b1bQ_np"
      },
      "source": [
        "# Vertex AI Vector Search - RAG Demo\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9uyNwTISc9u"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Before get started with the Vertex AI services, we need to setup the following.\n",
        "\n",
        "* Install Python SDK\n",
        "* Environment variables\n",
        "* Authentication (Colab only)\n",
        "* Enable APIs\n",
        "* Set IAM permissions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8eMxpb6-0n4"
      },
      "source": [
        "### Install the Vertex AI SDK\n",
        "\n",
        "Vertex AI APIs can be accessed with multiple ways including REST API and Python SDK. In this tutorial we will use the SDK."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7hUF_94TRTPb"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade --quiet --user google-cloud-aiplatform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5Xep4W9lq-Z"
      },
      "source": [
        "### Restart current runtime\n",
        "\n",
        "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which will restart the current kernel.\n",
        "\n",
        "For Colab users: you will see \"Your session crushed\" message when restarting the kernel, but it is expected. Continue to the following cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRvKdaPDTznN"
      },
      "outputs": [],
      "source": [
        "# Restart kernel after installs so that your environment can access the new packages\n",
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbmM4z7FOBpM"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>⚠️ The kernel is going to restart. In Colab or Colab Enterprise, you might see an error message that says \"Your session crashed for an unknown reason.\" This is expected. Please wait until it is finished before continuing to the next step. ⚠️</b>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnKVMQ7coUGQ"
      },
      "source": [
        "### Environment variables\n",
        "\n",
        "Sets environment variables. If asked, replace the following `[your-project-id]` with your project ID and run it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HPfsNnW1e5mm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e56092f1-29fa-4c55-f78e-50c2674ab847"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please set the project ID manually below\n"
          ]
        }
      ],
      "source": [
        "# get project ID\n",
        "PROJECT_ID = ! gcloud config get project\n",
        "PROJECT_ID = PROJECT_ID[0]\n",
        "LOCATION = \"us-central1\"\n",
        "if PROJECT_ID == \"(unset)\":\n",
        "    print(f\"Please set the project ID manually below\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2C0lUcDGoW_x"
      },
      "outputs": [],
      "source": [
        "# define project information\n",
        "if PROJECT_ID == \"(unset)\":\n",
        "    PROJECT_ID = \"uk-con-gcp-sbx-ukat01-012822\"  # @param {type:\"string\"}\n",
        "\n",
        "# generate an unique id for this session\n",
        "from datetime import datetime\n",
        "\n",
        "UID = datetime.now().strftime(\"%m%d%H%M\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLEgrr3ORwJH"
      },
      "source": [
        "### Authentication (Colab only)\n",
        "\n",
        "If you are running this notebook on Colab, you will need to run the following cell authentication. This step is not required if you are using Vertex AI Workbench as it is pre-authenticated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "p9iGiaF7RgZs"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "# if it's Colab runtime, authenticate the user with Google Cloud\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPd9NaBxn7ho"
      },
      "source": [
        "### Set IAM permissions\n",
        "\n",
        "Also, we need to add access permissions to the default service account for using those services.\n",
        "\n",
        "- Go to [the IAM page](https://console.cloud.google.com/iam-admin/) in the Console\n",
        "- Look for the principal for default compute service account. It should look like: `<project-number>-compute@developer.gserviceaccount.com`\n",
        "- Click the edit button at right and click `ADD ANOTHER ROLE` to add `Vertex AI User` and `Service Usage Admin` roles to the account.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hIbkmLEn2Z_"
      },
      "source": [
        "### Enable APIs\n",
        "\n",
        "Run the following to enable APIs for Compute Engine and Vertex AI with this Google Cloud project."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import aiplatform\n",
        "\n",
        "aiplatform.init(project=PROJECT_ID, location=LOCATION)"
      ],
      "metadata": {
        "id": "RivfdnfoYBWL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2feyXkRaovq"
      },
      "source": [
        "## Run a Query with Vector Search\n",
        "\n",
        "Finally it's ready to use Vector Search. To run a query, you need to get an embedding for a query item. For example, if you like to find products with similar names to \"cloudveil women's excursion short\", you need to get the embedding for it before running a query. In this tutorial, we will get the embedding from the `product-embs.json` file as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "EqS1XcVCbhT7"
      },
      "outputs": [],
      "source": [
        "from vertexai.language_models import TextEmbeddingModel\n",
        "def generate_text_embeddings(sentences) -> list:\n",
        "    model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko@003\")\n",
        "    embeddings = model.get_embeddings(sentences)\n",
        "    vectors = [embedding.values for embedding in embeddings]\n",
        "    return vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e31HB8_tr0II"
      },
      "source": [
        "With the `product_embs` dict, you can specify a product ID to get an embedding for it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yusFJLd954nH"
      },
      "outputs": [],
      "source": [
        "#query=[\"Allowed cost of online course\"]\n",
        "#query=[\"process for applying sick leave\"]\n",
        "query=[\"savings account with the best interest rate and suitable for someone under 16\"]\n",
        "qry_emb=generate_text_embeddings(query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBoEWB3TAsJp"
      },
      "source": [
        "### Run a Query\n",
        "\n",
        "Then, pass the embedding to `find_neighbors` function to find similar product names."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bUnjsDkWbMAa"
      },
      "outputs": [],
      "source": [
        "from vertexai.preview.generative_models import GenerativeModel, Part\n",
        "\n",
        "my_index_endpoint = aiplatform.MatchingEngineIndexEndpoint(index_endpoint_name=\"4381980447198937088\")\n",
        "\n",
        "# run query\n",
        "response = my_index_endpoint.find_neighbors(\n",
        "    deployed_index_id=\"vs_bank_prod_deployed_12041551\", queries=[qry_emb[0]], num_neighbors=10\n",
        ")\n",
        "\n",
        "# show the results\n",
        "# for idx, neighbor in enumerate(response[0]):\n",
        "#     print(f\"{neighbor.distance:.2f} {product_names[neighbor.id]}\")\n",
        "matching_ids = [neighbor.id for sublist in response for neighbor in sublist]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "sentence_file_path = \"bank_sentences_041224.json\"\n",
        "data = []\n",
        "with open(sentence_file_path) as file:\n",
        "  for line in file:\n",
        "    d = json.loads(line)\n",
        "    data.append(d)"
      ],
      "metadata": {
        "id": "XiDSCSdwm8Ny"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_context(ids,data):\n",
        "  concatenated_names = ''\n",
        "  for id in ids:\n",
        "    for entry in data:\n",
        "      # print(entry)\n",
        "      if entry['id'] == id:\n",
        "        concatenated_names += entry['sentence'] + \"\\n\"\n",
        "  return concatenated_names.strip()\n",
        "\n",
        "context = generate_context(matching_ids,data)\n",
        "print(context)"
      ],
      "metadata": {
        "id": "eSWkW1W7vFje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GenerativeModel(\"gemini-pro\")\n",
        "prompt=f\"Based on the context delimited in backticks, answer the query. ```{context}``` {query}\""
      ],
      "metadata": {
        "id": "XTkjZPVZslT-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prompt)"
      ],
      "metadata": {
        "id": "H3Ti-sBnk3CJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Np0U4vybhT7"
      },
      "outputs": [],
      "source": [
        "chat = model.start_chat(history=[])\n",
        "response = chat.send_message(prompt)\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_sXlLpysUtf"
      },
      "source": [
        "The `find_neighbors` function only takes milliseconds to fetch the similar items even when you have billions of items on the Index, thanks to the ScaNN algorithm. Vector Search also supports [autoscaling](https://cloud.google.com/vertex-ai/docs/vector-search/deploy-index-public#autoscaling) which can automatically resize the number of nodes based on the demands of your workloads."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDmv_HkObedQ"
      },
      "source": [
        "# IMPORTANT: Cleaning Up\n",
        "\n",
        "In case you are using your own Cloud project, not a temporary project on Qwiklab, please make sure to delete all the Indexes and Index Endpoints after finishing this tutorial. Otherwise the remaining objects would **incur unexpected costs**.\n",
        "\n",
        "If you used Workbench, you may also need to delete the Notebooks from [the console](https://console.cloud.google.com/vertex-ai/workbench)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QhInCv3sscAH"
      },
      "outputs": [],
      "source": [
        "# wait for a confirmation\n",
        "input(\"Press Enter to delete Index Endpoint and Index:\")\n",
        "\n",
        "# delete Index Endpoint\n",
        "my_index_endpoint.undeploy_all()\n",
        "my_index_endpoint.delete(force=True)\n",
        "\n",
        "# delete Index\n",
        "my_index.delete()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9OG7QbCmqqx"
      },
      "source": [
        "## Utilities\n",
        "\n",
        "It can take some time to create or deploy indexes, and in that time you might lose connection with the Colab runtime. If you lose connection, instead of creating or deploying your new index again, you can check [the Vector Search Console](https://console.cloud.google.com/vertex-ai/matching-engine/index-endpoints) and use the existing ones to continue.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8yeRRZrmyn1"
      },
      "source": [
        "### Get an existing Index\n",
        "\n",
        "To get an index object that already exists, replace the following `[numeric-index-id]` with the index ID and run the cell. You can check the ID on [the Vector Search Console > INDEXES tab](https://console.cloud.google.com/vertex-ai/matching-engine/indexes)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvdaNEw4mw2c"
      },
      "outputs": [],
      "source": [
        "my_index_id = \"8619498260647641088\"  # @param {type:\"string\"}\n",
        "my_index = aiplatform.MatchingEngineIndex(my_index_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87N_WmeDnPaX"
      },
      "source": [
        "### Get an existing Index Endpoint\n",
        "\n",
        "To get an index endpoint object that already exists, replace the following `[numeric-index-endpoint-id]` with the index endpoint ID and run the cell. You can check the ID on [the Vector Search Console > INDEX ENDPOINTS tab](https://console.cloud.google.com/vertex-ai/matching-engine/index-endpoints)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDz9ir72o44x"
      },
      "outputs": [],
      "source": [
        "my_index_endpoint_id = \"4381980447198937088\"  # @param {type:\"string\"}\n",
        "my_index_endpoint = aiplatform.MatchingEngineIndexEndpoint(my_index_endpoint_id)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "bank_rag_demo.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}